{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df72d332-a1bf-413b-89a2-d48da876b1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as sqlFn\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76067c73-c57d-477b-ba6e-6b5a49220886",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/28 16:52:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da6abe21-3323-4f52-8a17-7ee563b9c057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Product Id: string (nullable = true)\n",
      " |-- Customer Id: string (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Source: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- Sales Id: long (nullable = false)\n",
      "\n",
      "root\n",
      " |-- Product Id: integer (nullable = true)\n",
      " |-- Product Name: string (nullable = true)\n",
      " |-- Product Price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salesDF = spark.read.format(\"csv\") \\\n",
    "    .option(\"inferschema\",\"true\").option(\"header\",\"true\") \\\n",
    "    .load(\"sales.csv\").withColumn(\"Sales Id\", monotonically_increasing_id())\n",
    "\n",
    "productsDF = spark.read.format(\"csv\") \\\n",
    "    .option(\"inferschema\",\"true\").option(\"header\",\"true\").load(\"products.csv\")\n",
    "\n",
    "# Data Format:\n",
    "salesDF.printSchema()\n",
    "productsDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f700304-3150-4c4a-866d-84a9ed8e0087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-------------------+--------+----------+--------+--------+\n",
      "|Product Id|Customer Id|               Date|Location|    Source|Quantity|Sales Id|\n",
      "+----------+-----------+-------------------+--------+----------+--------+--------+\n",
      "|         1|          A|2023-01-01 00:00:00|   India|    Swiggy|       1|       0|\n",
      "|         2|          A|2022-01-01 00:00:00|   India|    Swiggy|       2|       1|\n",
      "|         2|          A|2023-01-07 00:00:00|   India|    Swiggy|       3|       2|\n",
      "|         3|          A|2023-01-10 00:00:00|   India|Restaurant|       1|       3|\n",
      "|         3|          A|2022-01-11 00:00:00|   India|    Swiggy|       1|       4|\n",
      "+----------+-----------+-------------------+--------+----------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+------------+-------------+\n",
      "|Product Id|Product Name|Product Price|\n",
      "+----------+------------+-------------+\n",
      "|         1|       PIZZA|        100.0|\n",
      "|         2|     Chowmin|        150.0|\n",
      "|         3|    sandwich|        120.0|\n",
      "|         4|        Dosa|        110.0|\n",
      "|         5|     Biryani|         80.0|\n",
      "|         6|       Pasta|        180.0|\n",
      "|         7|     Boogers|        999.0|\n",
      "+----------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sneak peek:\n",
    "salesDF.show(5)\n",
    "productsDF.show()\n",
    "\n",
    "# It's SQL'ing Time!\n",
    "salesDF.createOrReplaceTempView(\"sales\")\n",
    "productsDF.createOrReplaceTempView(\"products\")\n",
    "\n",
    "\n",
    "# joinQuery = \"\"\"\n",
    "# select\n",
    "#     `Sales Id`,\n",
    "#     products.`Product Id`,\n",
    "#     `Product Name`,\n",
    "#     `Customer Id`,\n",
    "#     `Date`,\n",
    "#     `Location`,\n",
    "#     `Source`,\n",
    "#     `Quantity`,\n",
    "#     `Product Price`\n",
    "# from\n",
    "#     sales full outer join products on sales.`Product Id` = products.`Product Id`\n",
    "# \"\"\"\n",
    "# spark.sql(joinQuery).createOrReplaceTempView(\"completeTable\")\n",
    "\n",
    "joinedDF = salesDF.join(productsDF, salesDF[\"Product Id\"] == productsDF[\"Product Id\"], \"fullouter\") \\\n",
    "    .drop(salesDF[\"Product Id\"]) # Product Id column is redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a88a9137-9361-43a2-9cc8-68cf5017b201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+--------+------+--------+--------+----------+------------+-------------+\n",
      "|Customer Id|Date|Location|Source|Quantity|Sales Id|Product Id|Product Name|Product Price|\n",
      "+-----------+----+--------+------+--------+--------+----------+------------+-------------+\n",
      "|       NULL|NULL|    NULL|  NULL|    NULL|     117|      NULL|        NULL|         NULL|\n",
      "|       NULL|NULL|    NULL|  NULL|    NULL|    NULL|         7|     Boogers|        999.0|\n",
      "+-----------+----+--------+------+--------+--------+----------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Anomalies:\n",
    "\n",
    "# query = \"\"\"\n",
    "# select\n",
    "#     *\n",
    "# from\n",
    "#     completeTable\n",
    "# where\n",
    "#     `Sales Id` is null or\n",
    "#     `Product Id` is null or\n",
    "#     `Product Name` is null or\n",
    "#     `Customer Id` is null or\n",
    "#     `Date` is null or\n",
    "#     `Location` is null or\n",
    "#     `Source` is null or\n",
    "#     `Quantity` is null or\n",
    "#     `Product Price` is null\n",
    "# \"\"\" \n",
    "# spark.sql(query).show()\n",
    "\n",
    "# Cached joinedDF as an action is to be performed \n",
    "nullsDF = joinedDF.cache().filter(' is null or '.join(f\"`{col}`\" for col in joinedDF.columns) + \"is null\")\n",
    "\n",
    "nullsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aff43276-48cc-4665-9bb9-c8b51d72bac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean NULL record:\n",
    "\n",
    "# filter = \"\"\"\n",
    "# select * from completeTable\n",
    "# where `Sales Id` is null or `Sales Id` != 117\n",
    "# \"\"\"\n",
    "# table = spark.sql(filter)\n",
    "\n",
    "# # To persist/cache or to not?\n",
    "# table.createOrReplaceTempView(\"completeTable\")\n",
    "\n",
    "completeDF = joinedDF.filter((joinedDF[\"Sales Id\"]!=117) | (joinedDF[\"Sales Id\"].isNull())).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "435a0d31-47d5-430f-a650-0ca7f8a1a9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|Customer Id|Total Spent|\n",
      "+-----------+-----------+\n",
      "|          B|    19440.0|\n",
      "|          C|     6560.0|\n",
      "|          A|    13830.0|\n",
      "|          E|    15630.0|\n",
      "|          D|     4280.0|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q. Total amount spend by each customer:\n",
    "\n",
    "# query = \"\"\"\n",
    "# select\n",
    "#     `Customer Id`,\n",
    "#     sum(ifnull(`Product Price`,0)*`Quantity`) as `Total Spent`,\n",
    "#     sum(`Quantity`) as `Items Bought`\n",
    "# from\n",
    "#     completeTable\n",
    "# where\n",
    "#     `Sales Id` is not null\n",
    "# group by\n",
    "#     `Customer Id`\n",
    "# order by\n",
    "#     `Total Spent` desc\n",
    "# \"\"\"\n",
    "# spark.sql(query).show()\n",
    "\n",
    "# `Sales Id` is not null -> (Customer Id, Quantity, Product Price) not null\n",
    "completeDF.where(completeDF[\"Sales Id\"].isNotNull()) \\\n",
    "    .groupBy(completeDF[\"Customer Id\"]) \\\n",
    "    .agg(sqlFn.sum(completeDF[\"Product Price\"]*completeDF[\"Quantity\"]).alias(\"Total Spent\")) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f5f5a2b-f98e-46b2-bab1-44daffe70040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "|Product Name|Total Spent|\n",
      "+------------+-----------+\n",
      "|       PIZZA|     5600.0|\n",
      "|       Pasta|     3600.0|\n",
      "|    sandwich|    28560.0|\n",
      "|     Biryani|     2000.0|\n",
      "|        Dosa|     3630.0|\n",
      "|     Boogers|        0.0|\n",
      "|     Chowmin|    16350.0|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q. Total spend on each Product: (Assumption: Product Id 1-to-1 Product Name)\n",
    "\n",
    "# query = \"\"\"\n",
    "# select\n",
    "#     `Product Name`,\n",
    "#     sum(ifnull(`Product Price`,0)*ifnull(`Quantity`,0)) as `Total Spent`,\n",
    "#     sum(ifnull(`Quantity`,0)) as `Units Bought`\n",
    "# from\n",
    "#     completeTable\n",
    "# where\n",
    "#     `Product Id` is not null\n",
    "# group by\n",
    "#     `Product Name`\n",
    "# order by\n",
    "#     `Total Spent` desc\n",
    "# \"\"\"\n",
    "# spark.sql(query).show()\n",
    "\n",
    "completeDF.where(completeDF[\"Product Id\"].isNotNull()) \\\n",
    "    .groupBy(completeDF[\"Product Name\"]) \\\n",
    "    .agg( \\\n",
    "        sqlFn.sum(sqlFn.ifnull(completeDF[\"Product Price\"],sqlFn.lit(0))*sqlFn.ifnull(completeDF[\"Quantity\"],sqlFn.lit(0))) \\\n",
    "        .alias(\"Total Spent\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a425a536-57bd-4143-813c-ada88922fbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------+------------+------------+\n",
      "|Year|Month|Total Spent|Total Orders|Items Bought|\n",
      "+----+-----+-----------+------------+------------+\n",
      "|2022|    1|     1860.0|           5|          13|\n",
      "|2022|    2|     6470.0|           9|          55|\n",
      "|2022|    3|      880.0|           3|           7|\n",
      "|2022|    5|     1890.0|           5|          13|\n",
      "|2022|    6|     2640.0|           5|          18|\n",
      "|2022|    7|      950.0|           3|           7|\n",
      "|2022|   11|     1560.0|           3|          12|\n",
      "|2023|    1|     6740.0|          18|          50|\n",
      "|2023|    2|    15680.0|          15|         134|\n",
      "|2023|    3|      880.0|           5|           8|\n",
      "|2023|    5|    10910.0|          18|          81|\n",
      "|2023|    6|     5590.0|          18|          46|\n",
      "|2023|    7|     1590.0|           5|          15|\n",
      "|2023|   11|     2100.0|           5|          22|\n",
      "+----+-----+-----------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q. Total amount of sales in each month:\n",
    "\n",
    "# query = \"\"\"\n",
    "# select\n",
    "#     year(`Date`) as Year,\n",
    "#     month(`Date`) as Month,\n",
    "#     sum(ifnull(`Product Price`,0)*Quantity) as `Total Spent`,\n",
    "#     sum(`Quantity`) as `Items Bought`\n",
    "# from\n",
    "#     completeTable\n",
    "# where\n",
    "#     `Date` is not null\n",
    "# group by\n",
    "#     year(`Date`), month(`Date`)\n",
    "# order by\n",
    "#     year(`Date`) asc, month(`Date`) asc\n",
    "# \"\"\"\n",
    "\n",
    "# spark.sql(query).show()\n",
    "\n",
    "completeDF.where(completeDF[\"Sales Id\"].isNotNull()) \\\n",
    "    .groupBy(\n",
    "        sqlFn.year(completeDF[\"Date\"]).alias(\"Year\"),\n",
    "        sqlFn.month(completeDF[\"Date\"]).alias(\"Month\")\n",
    "    ) \\\n",
    "    .agg(\n",
    "        sqlFn.sum(completeDF[\"Product Price\"]*completeDF[\"Quantity\"]).alias(\"Total Spent\"),\n",
    "        sqlFn.count(completeDF[\"Sales Id\"]).alias(\"Total Orders\"),\n",
    "        sqlFn.sum(completeDF[\"Quantity\"]).alias(\"Items Bought\")\n",
    "    ).orderBy(\"Year\",\"Month\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd92bdee-42b0-4d89-9e4f-7caebe03c322",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+------------+\n",
      "|Year|Total Spent|Items Bought|\n",
      "+----+-----------+------------+\n",
      "|2023|    43490.0|         356|\n",
      "|2022|    16250.0|         125|\n",
      "+----+-----------+------------+\n",
      "\n",
      "Average time:  0.275629506111145\n"
     ]
    }
   ],
   "source": [
    "# Q. Yearly Sales:\n",
    "\n",
    "# query = \"\"\"\n",
    "# select\n",
    "#     year(`Date`) as Year,\n",
    "#     sum(ifnull(`Product Price`,0)*Quantity) as `Total Spent`,\n",
    "#     sum(`Quantity`) as `Items Bought`\n",
    "# from\n",
    "#     completeTable\n",
    "# where\n",
    "#     `Date` is not null\n",
    "# group by\n",
    "#     year(`Date`)\n",
    "# order by\n",
    "#     year(`Date`) asc\n",
    "# \"\"\"\n",
    "# spark.sql(query).show()\n",
    "\n",
    "\n",
    "tests = 100\n",
    "avg = 0\n",
    "for t in range(1,tests+1):\n",
    "    start = time.time()\n",
    "\n",
    "\n",
    "    completeDF.where(completeDF[\"Sales Id\"].isNotNull()) \\\n",
    "    .groupBy(sqlFn.year(\"Date\").alias(\"Year\")) \\\n",
    "    .agg(\n",
    "        sqlFn.sum(completeDF[\"Product Price\"] * completeDF[\"Quantity\"]).alias(\"Total Spent\"),\n",
    "        sqlFn.sum(\"Quantity\").alias(\"Items Bought\")\n",
    "    ).show()\n",
    "    \n",
    "    if (t!= tests):\n",
    "        clear_output()\n",
    "\n",
    "    end = time.time()\n",
    "    avg = (avg*(t-1) + (end-start))/t\n",
    "print(\"Average time: \",avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39cb0d7c-b57a-4431-ae45-d03c02e9eede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----------+------------+\n",
      "|Year|Quarter|Total Spent|Items Bought|\n",
      "+----+-------+-----------+------------+\n",
      "|2022|    1.0|     8330.0|          68|\n",
      "|2022|    2.0|     5410.0|          38|\n",
      "|2022|    3.0|      950.0|           7|\n",
      "|2022|    4.0|     1560.0|          12|\n",
      "|2023|    1.0|    22420.0|         184|\n",
      "|2023|    2.0|    17380.0|         135|\n",
      "|2023|    3.0|     1590.0|          15|\n",
      "|2023|    4.0|     2100.0|          22|\n",
      "+----+-------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q. Quarterly Sales:\n",
    "\n",
    "# query = \"\"\"\n",
    "# select\n",
    "#     year(`Date`) as Year,\n",
    "#     round((month(`Date`)-1)/4,0)+1 as Quarter,\n",
    "#     sum(ifnull(`Product Price`,0)*Quantity) as `Total Spent`,\n",
    "#     sum(Quantity) as `Items Bought`\n",
    "# from\n",
    "#     completeTable\n",
    "# where\n",
    "#     `Date` is not null\n",
    "# group by\n",
    "#     year(`Date`), round((month(`Date`)-1)/4,0)+1\n",
    "# order by\n",
    "#     year(`Date`), Quarter\n",
    "# \"\"\"\n",
    "\n",
    "# spark.sql(query).show()\n",
    "\n",
    "completeDF.where(completeDF[\"Sales Id\"].isNotNull()) \\\n",
    "    .groupBy(\n",
    "        sqlFn.year(\"Date\").alias(\"Year\"), \n",
    "        (sqlFn.round((sqlFn.month(\"Date\")-sqlFn.lit(1)) / sqlFn.lit(4),0) + 1).alias(\"Quarter\")\n",
    "    ) \\\n",
    "    .agg(\n",
    "        sqlFn.sum(completeDF[\"Product Price\"] * completeDF[\"Quantity\"]).alias(\"Total Spent\"),\n",
    "        sqlFn.sum(\"Quantity\").alias(\"Items Bought\")\n",
    "    ).orderBy(\"Year\",\"Quarter\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20aa91ae-2e10-44f9-81a9-6960675870b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-------------+\n",
      "|Product Id|Product Name|Orders Placed|\n",
      "+----------+------------+-------------+\n",
      "|         1|       PIZZA|           21|\n",
      "|         6|       Pasta|            6|\n",
      "|         3|    sandwich|           48|\n",
      "|         5|     Biryani|            6|\n",
      "|         4|        Dosa|           12|\n",
      "|         7|     Boogers|            0|\n",
      "|         2|     Chowmin|           24|\n",
      "+----------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q. Total number of orders by each category: \n",
    "\n",
    "# query = \"\"\"\n",
    "# select\n",
    "#     `Product Id`,\n",
    "#     `Product Name`,\n",
    "#     count(`Sales Id`) as `Orders Placed`\n",
    "# from\n",
    "#     completeTable\n",
    "# where\n",
    "#     `Product Id` is not null\n",
    "# group by\n",
    "#     `Product Id`,`Product Name`\n",
    "# \"\"\"\n",
    "# spark.sql(query).show()\n",
    "\n",
    "completeDF.where(completeDF[\"Sales Id\"].isNotNull()) \\\n",
    "    .groupBy(\n",
    "        sqlFn.year(\"Date\").alias(\"Year\"), \n",
    "        (sqlFn.round((sqlFn.month(\"Date\")-sqlFn.lit(1)) / sqlFn.lit(4),0) + 1).alias(\"Quarter\")\n",
    "    ) \\\n",
    "    .agg(\n",
    "        sqlFn.sum(completeDF[\"Product Price\"] * completeDF[\"Quantity\"]).alias(\"Total Spent\"),\n",
    "        sqlFn.sum(\"Quantity\").alias(\"Items Bought\")\n",
    "    ).orderBy(\"Year\",\"Quarter\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e907923e-24b1-4cbc-8d73-3b25a92e4fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+------------+------------+\n",
      "|Product Id|Product Name|Items Bought|Total Orders|\n",
      "+----------+------------+------------+------------+\n",
      "|         3|    sandwich|         238|          48|\n",
      "|         2|     Chowmin|         109|          24|\n",
      "|         1|       PIZZA|          56|          21|\n",
      "|         4|        Dosa|          33|          12|\n",
      "|         5|     Biryani|          25|           6|\n",
      "+----------+------------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q. Top 5 ordered items:\n",
    "\n",
    "# query = \"\"\"\n",
    "# select\n",
    "#     `Product Id`,\n",
    "#     `Product Name`,\n",
    "#     ifnull(sum(Quantity),0) as `Items Bought`,\n",
    "#     count(`Sales Id`) as Orders\n",
    "# from\n",
    "#     completeTable\n",
    "# where\n",
    "#     `Product Id` is not null\n",
    "# group by\n",
    "#     `Product Id`, `Product Name`\n",
    "# order by\n",
    "#     `Items Bought` desc\n",
    "# limit\n",
    "#     5\n",
    "# \"\"\"\n",
    "# spark.sql(query).show()\n",
    "\n",
    "completeDF.where(completeDF[\"Product Id\"].isNotNull()) \\\n",
    "    .groupBy(completeDF[\"Product Id\"]) \\\n",
    "    .agg(\n",
    "        sqlFn.max(\"Product Name\").alias(\"Product Name\"), \n",
    "        sqlFn.sum(\"Quantity\").alias(\"Items Bought\"),\n",
    "        sqlFn.count(completeDF[\"Sales Id\"]).alias(\"Total Orders\")      \n",
    "    ).orderBy([\"Total Orders\"],ascending=[0]).limit(5).show() # Order by \"Items Bought\" or \"Total Orders\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd79ba4b-fc9d-48ee-a6d6-947b60e7f110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------------+\n",
      "|Customer Id|Frequency of Purchases|\n",
      "+-----------+----------------------+\n",
      "|          B|                    36|\n",
      "|          C|                    18|\n",
      "|          A|                    33|\n",
      "|          E|                    18|\n",
      "|          D|                    12|\n",
      "+-----------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q. Frequency of Customer visit:\n",
    "\n",
    "# query = \"\"\"\n",
    "# select\n",
    "#     `Customer Id`,\n",
    "#     count(`Sales Id`) as `Frequency of Purchases`\n",
    "# from\n",
    "#     completeTable\n",
    "# where\n",
    "#     `Customer Id` is not null\n",
    "# group by\n",
    "#     `Customer Id`\n",
    "# \"\"\"\n",
    "# spark.sql(query).show()\n",
    "\n",
    "completeDF.where(completeDF[\"Customer Id\"].isNotNull()) \\\n",
    "    .groupBy(\"Customer Id\") \\\n",
    "    .agg(\n",
    "        sqlFn.count(completeDF[\"Sales Id\"]).alias(\"Frequency of Purchases\")\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39f56f3b-ec17-4ea3-9baa-79976833752f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|Location|Country Sales Amount|\n",
      "+--------+--------------------+\n",
      "|   India|             19600.0|\n",
      "|     USA|              7310.0|\n",
      "|      UK|             32830.0|\n",
      "+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q. Total sales by each country:\n",
    "\n",
    "# query = \"\"\"\n",
    "# select\n",
    "#     `Location`,\n",
    "#     sum(ifnull(`Product Price`,0)*`Quantity`) as `Country Sales Amount`\n",
    "# from\n",
    "#     completeTable\n",
    "# where\n",
    "#     `Location` is not null\n",
    "# group by\n",
    "#      `Location`\n",
    "# \"\"\"\n",
    "# spark.sql(query).show()\n",
    "\n",
    "completeDF.where(completeDF[\"Sales Id\"].isNotNull()) \\\n",
    "    .groupBy(\"Location\") \\\n",
    "    .agg(\n",
    "        sqlFn.sum(completeDF[\"Product Price\"]*completeDF[\"Quantity\"]).alias(\"Country Sales Amount\")\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c349b2c-f918-4210-9b98-84ca2fe13b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+\n",
      "|    Source|Source Sales Amount|\n",
      "+----------+-------------------+\n",
      "|    Swiggy|            20260.0|\n",
      "|Restaurant|            18580.0|\n",
      "|    zomato|            20900.0|\n",
      "+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q. Total sales by order source:\n",
    "\n",
    "# query = \"\"\"\n",
    "# select\n",
    "#     `Source`,\n",
    "#     sum(ifnull(`Product Price`,0)*`Quantity`) as `Source Sales Amount`,\n",
    "#     count(`Sales Id`) as Orders\n",
    "# from\n",
    "#     completeTable\n",
    "# where\n",
    "#     `Source` is not null\n",
    "# group by\n",
    "#      `Source`\n",
    "# \"\"\"\n",
    "\n",
    "# spark.sql(query).show()\n",
    "\n",
    "completeDF.where(completeDF[\"Sales Id\"].isNotNull()) \\\n",
    "    .groupBy(\"Source\") \\\n",
    "    .agg(\n",
    "        sqlFn.sum(completeDF[\"Product Price\"]*completeDF[\"Quantity\"]).alias(\"Source Sales Amount\")\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6206afa8-3172-42db-a8ce-a01474f12dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
